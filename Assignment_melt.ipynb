{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f48aa0-98b6-4284-930c-9c3a1f88bc6f",
   "metadata": {},
   "source": [
    "# Inlämningsuppgift / Assignment\n",
    "The assignment is divided upp into 3 parts; \n",
    "1. Numpy\n",
    "2. Pandas\n",
    "3. Exploration\n",
    "\n",
    "Each section has it's own instructions to follow and questions that must be answered. Please observe that if you use any additional libraries apart from **numpy**, **pandas** or **matplotlib**, you must include an **environment.yml** file such that I can duplicate your conda environment. \n",
    "\n",
    "Deadline for submitting this assignment is `Monday Feb 21st at 23:59`.\n",
    "\n",
    "#### List of files\n",
    " - *Assignment.ipynb* - which is to be renamed with your name and course town as such: **Firstname.Lastname_TOWN** where TOWN is to be replaced with **MO** for Malmö or **HMS** for Halmstad.\n",
    " - *countries.csv*\n",
    " - *covid-countries-data.csv*\n",
    " - *whatsapp analysis example.pdf*\n",
    "\n",
    "### Grading\n",
    "In order to obtain a **G** you must: \n",
    ">- Complete the whole *Numpy* section. \n",
    ">- Complete *Part 2*, except the questions marked **Q - VG**. \n",
    ">- Complete *Part 3*, except *Step 4* and the **VG** question in *Step 5*.\n",
    "\n",
    "To obtain **VG** you must:\n",
    ">- Complete all of the steps required in the **G** section. \n",
    ">- Complete the **Q - VG** questions in *Part 2*. \n",
    ">- Complete *Step 4* in *Part 3*.\n",
    "\n",
    "##### Resources: \n",
    "- [Numpy official tutorial](https://numpy.org/doc/stable/user/quickstart.html)\n",
    "- [Matplotlib](https://github.com/rougier/matplotlib-tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0dc309-2a25-429d-bab0-6a5f40800395",
   "metadata": {},
   "source": [
    "## Part 1 - Numpy\n",
    "The objective of this part of the assignment is to develop a solid understanding of Numpy array operations. In this assignment you will:\n",
    "> \n",
    "> 1. Pick 5 interesting Numpy array functions by going through the documentation: https://numpy.org/doc/stable/reference/routines.html\n",
    "> 2. Run and modify this Jupyter notebook to illustrate their usage (some explanation and 3 examples for each function). Use your imagination to come up with interesting and unique examples.\n",
    "> 3. Do not use any of the functions mentioned on slide 11 of lecture notes *6. Datahantering och Numpy*. Choose something new!\n",
    "> 4. Try to give this section an interesting title_labels & subtitle e.g. \"*5 Numpy functions you didn't know you needed*\", \"*Interesting ways to create Numpy arrays*\" etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d870fac-d1db-4401-9eaf-c8be3a6f80ae",
   "metadata": {},
   "source": [
    "## Bitwise functions in numpy\n",
    "\n",
    "\n",
    "Bitwise functions does operation on the binary representation of numbers. \n",
    "- bitwise_and \n",
    "- bitwise_or\n",
    "- bitwise_xor\n",
    "- packbits\n",
    "- matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e361a6-3696-433d-ac11-1e40d4716cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71eff0-208b-4721-bdad-d1660aa4986c",
   "metadata": {},
   "source": [
    "List of functions explained \n",
    "1. bitwise_and - When both numbers in binary representation is equal the new value has that number, if they're not equal it's 0. Follows logical and\n",
    "2. bitwise_or - When either one of the value in the binary representation is a 1 or both has a 1 the new value gets a 1, if both are 0 the new value is 0. Follows logical or\n",
    "3. bitwise_xor - When either one is a 1 in the binary representation the new value is 1, if both are either 1 or 0 the new value is 0. \n",
    "4. linalg.det - a linear algebra function that calculates the determinant\n",
    "5. matmul -a linear algebra function to calculate the matrix multiplication between two "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb269f8",
   "metadata": {},
   "source": [
    "## bitwise_and\n",
    "\n",
    "Bitwise operation uses an array of values that's either true or false. It can be either an array filled with true and false values or a number in it's binary representation.\n",
    "\n",
    "Takes two array like arguments as input, an optional \"out\" and \"where\".\n",
    "\n",
    "Out is a location where the result then will be stored and therefor must have the same shape the inputs outputs.\n",
    "\n",
    "Where is a condition that broadcasted over the input. Where the condition is True, the output array will be set to the ufunc result and otherwise it'll retain it's original value.\n",
    "\n",
    "The output of the  function is an ndarray or a scalar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d5393fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = 11\n",
    "B = 13\n",
    "np.bitwise_and(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ebbab9",
   "metadata": {},
   "source": [
    "In the code above:\n",
    "\n",
    "    A = 1011 in binary\n",
    "\n",
    "    B = 1101 in binary\n",
    "\n",
    "what bitwise_and does follows logical and, which means that it looks at each seperate value and if both is equal to true, the output value is also true.\n",
    "\n",
    "reading left to right:\n",
    "\n",
    "    first number = 1 because both values are 1\n",
    "\n",
    "    second number = 0 because A is 0\n",
    "\n",
    "    third number = 0 because B is 0\n",
    "\n",
    "    fourth umber = 1 because both are 1\n",
    "    \n",
    "That leaves us with 1001 in binary which corresponds to 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7e8ad03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [True, False, False, True]\n",
    "B = [False, True, False, True]\n",
    "np.bitwise_and(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cccccd",
   "metadata": {},
   "source": [
    "following the same pattern as with the binary representation we get:\n",
    "\n",
    "[False, False, False, True] because only the last element in both arrays are True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "44145e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = 5\n",
    "B = [True, False, True, False]\n",
    "np.bitwise_and(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86277e6",
   "metadata": {},
   "source": [
    "notable this also works by combining a number and a list of true and false values (B = 0101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b2a31d58",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-231-7d8dbe7886da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "A = 5.0\n",
    "B = [True, False, True, False]\n",
    "np.bitwise_and(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "48e2fe3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-269-973ba4b3436d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,1) doesn't match the broadcast shape (1,4)"
     ]
    }
   ],
   "source": [
    "A = 5\n",
    "B = [True, False, True, False]\n",
    "C = np.ndarray(shape=(1,1))\n",
    "np.bitwise_and(A, B, out=C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff936cc",
   "metadata": {},
   "source": [
    "bitwise doesn't work for types that cannot be represented as a binary-valued array. This is true for bitwise_or and bitwise_xor aswell\n",
    "bitwise also throws a ValueError when the output shape is doesn't match the broadcasted shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67635863",
   "metadata": {},
   "source": [
    "## bitwise_or"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6281031",
   "metadata": {},
   "source": [
    "bitwise_or works that if either of the values are a 1, the new value has a 1 in that location.\n",
    "\n",
    "It can be either an array filled with true and false values or a number in it's binary representation.\n",
    "\n",
    "Takes two array like arguments as input, an optional \"out\" and \"where\".\n",
    "\n",
    "Out is a location where the result then will be stored and therefor must have the same shape the inputs outputs.\n",
    "\n",
    "Where is a condition that broadcasted over the input. Where the condition is True, the output array will be set to the ufunc result and otherwise it'll retain it's original value.\n",
    "\n",
    "The output of the  function is an ndarray or a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a675d7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = 11\n",
    "B = 13\n",
    "np.bitwise_or(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a6b65",
   "metadata": {},
   "source": [
    "A = 1011\n",
    "\n",
    "B = 1101\n",
    "\n",
    "first number = 1 because both are 1\n",
    "\n",
    "second number = 1 because B is 1\n",
    "\n",
    "third number = 1 because A is 1\n",
    "\n",
    "fourth number = 1 because both are 1\n",
    "\n",
    "that gives us 1111 which equals 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7a588eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [True, True, False, False]\n",
    "B = [True, False, False, True]\n",
    "np.bitwise_or(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae62f3",
   "metadata": {},
   "source": [
    "first element = True since both are true\n",
    "\n",
    "second element = True since A is true\n",
    "\n",
    "third element = False since both are false\n",
    "\n",
    "fourth element = True since B is true\n",
    "\n",
    "that gives us [True, True, False, True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531c76a",
   "metadata": {},
   "source": [
    "## bitwise_xor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff815ef",
   "metadata": {},
   "source": [
    "bitwise_xor gives a value 1 if either of the values are 1 but not both.\n",
    "It can be either an array filled with true and false values or a number in it's binary representation.\n",
    "Takes two array like arguments as input, an optional \"out\" and \"where\".\n",
    "Out is a location where the result then will be stored and therefor must have the same shape the inputs outputs.\n",
    "Where is a condition that broadcasted over the input. Where the condition is True, the output array will be set to the ufunc result and otherwise it'll retain it's original value.\n",
    "The output of the  function is an ndarray or a scalar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "72c5bc5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The 'out' tuple must have exactly one entry per ufunc output",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-261-c5b2fc3a9539>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_xor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: The 'out' tuple must have exactly one entry per ufunc output"
     ]
    }
   ],
   "source": [
    "A = 11\n",
    "B = 13\n",
    "np.bitwise_xor(A, B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c376366",
   "metadata": {},
   "source": [
    "A = 1011\n",
    "\n",
    "B = 1101\n",
    "\n",
    "first number = 0 because both are 1\n",
    "\n",
    "second number = 1 because A is 1 and B is 0\n",
    "\n",
    "third number = 1 because B is 1 and A is 0\n",
    "\n",
    "fourth number = 0 because both are 1\n",
    "\n",
    "that gives us 0110 which equals 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "90399f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [True, True, False, False]\n",
    "B = [True, False, False, True]\n",
    "np.bitwise_xor(A, B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31ac166",
   "metadata": {},
   "source": [
    "first element = False since both are true\n",
    "\n",
    "second element = True since A is true and B is false\n",
    "\n",
    "third element = False since both are false\n",
    "\n",
    "fourth element = True since B is true and A is false\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81302cc6",
   "metadata": {},
   "source": [
    "## linalg.det"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd8cd05",
   "metadata": {},
   "source": [
    "lingalg.det is a function to calculate the determinant of an array. The determinant is the factor by which space is scaled in a linear transformation\n",
    "\n",
    "the function takes an array (or a stack of matrices) as input and gives an float or an array as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "084d86cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_unary_dispatcher() got an unexpected keyword argument 'out'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-260-59f24b5cc5e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdet\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _unary_dispatcher() got an unexpected keyword argument 'out'"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "np.linalg.det(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868be0c",
   "metadata": {},
   "source": [
    "determinant of a 2x2 matrix is calculated by doing \n",
    "\n",
    "a * d - b * c \n",
    "\n",
    "=\n",
    "\n",
    "1 * 4 - 2 * 3= -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f7002d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2., -3., -8.])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[[1, 2], [3, 4]], [[1, 2], [2, 1]], [[1, 3], [3, 1]]])\n",
    "np.linalg.det(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eb8f09",
   "metadata": {},
   "source": [
    "input is a stack of matrices and output is an array with values for each matrix\n",
    "\n",
    "first element is same as example above\n",
    "\n",
    "second element is  1 * 1 - 2 * 2 = -3\n",
    "\n",
    "third element is 1 * 1 - 3 * 3 = -8\n",
    "\n",
    "which gives us the array [-2., -3., -8.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "443b8a2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Last 2 dimensions of the array must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-251-5a3abbed6da5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdet\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mB:\\Program\\Anaconda\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mdet\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   2153\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m     \u001b[0m_assert_stacked_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2155\u001b[1;33m     \u001b[0m_assert_stacked_square\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2156\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mB:\\Program\\Anaconda\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_assert_stacked_square\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Last 2 dimensions of the array must be square'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_assert_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2,3], [1,3, 4]])\n",
    "np.linalg.det(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d09ebe",
   "metadata": {},
   "source": [
    "The determinant can only be calculated with a square matrix, if function is called with non square matrix as parameter a LinAlgError will be thrown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171bdc3",
   "metadata": {},
   "source": [
    "## matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c89d5a",
   "metadata": {},
   "source": [
    "matmul is function to do matrix multiplication on. Takes in 2 arrays and output is of array type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "163dfc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 1],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "b = np.array([[4, 1],\n",
    "              [2, 2]])\n",
    "np.matmul(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9e8df2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "b = np.array([1, 2])\n",
    "np.matmul(a, b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c8fcf8",
   "metadata": {},
   "source": [
    "gives you an array like object as output of the two matrixes multiplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "15fe6835",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-257-54557808a7b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m               [0, 1]])\n\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "b = np.array([1, 2,3])\n",
    "np.matmul(a, b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765db4e3",
   "metadata": {},
   "source": [
    "If the dimensions needed for matrix multiplication doesn't match a ValueError will be thrown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ebc46-7ffa-4475-a7bc-ec6d673d3663",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Summarize what was covered in *Part 1*, and where to go next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c39b06-75c9-49e9-9100-d753c2c176de",
   "metadata": {},
   "source": [
    "\n",
    "bitwise operations are element wise operation done on arrays that have a binary representation. \n",
    "\n",
    "Using function like bitwise_and that follows logical and which menas that when both values are the same value, the new value is true.\n",
    "\n",
    "bitwise_or returns true to the new position when either both or one of the values are true otherwise false\n",
    "\n",
    "bitwise_xor returns true to the new position when only one of the values are true \n",
    "\n",
    "The bitwise functions can be used to help solve problems more efficiently like the 8 queens puzzle\n",
    "\n",
    "https://en.wikipedia.org/wiki/Eight_queens_puzzle\n",
    "\n",
    "bitwise functions breaks when the input cannot be represented as a binary-valued array or when the out input is not the same shape as the broadcasted output\n",
    "\n",
    "for future reading look at the other bitwiwse operation such as invert, left_shift and right_shift at https://numpy.org/doc/stable/reference/routines.bitwise.html\n",
    "\n",
    "Want a deeper understanding look at mit lecture in their \"Performance Engineering of Software Systems\" class från 2018 https://www.youtube.com/watch?v=ZusiKXcz_ac\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7629e3-37a6-4d0d-9f1d-f47e49bc2a30",
   "metadata": {},
   "source": [
    "det calculates the determinant of the given array. The array must be a square matrix otherwise an error will be thrown. Output is a scalar or an ndarray\n",
    "\n",
    "matmul calculates a matrix multiplication of given arrays either 2 or a stack of them. Error will be thrown when inputs have a dimension mismatch. Output is a ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb55e4-9257-4ce3-be73-8a7ab8843108",
   "metadata": {},
   "source": [
    "# Part 2 - Pandas\n",
    "\n",
    "As you go through *Part 2*, you will find a **???** in certain places. To complete this part of the assignment, you must replace all the **???** with appropriate values, expressions or statements to ensure that the notebook runs properly end-to-end. \n",
    "\n",
    "Some things to keep in mind:\n",
    "\n",
    "* Make sure to run all the code cells, otherwise you may get errors like `NameError` for undefined variables.\n",
    "* Do not change variable names, delete cells or disturb other existing code. It may cause problems during evaluation.\n",
    "* In some cases, you may need to add some code cells or new statements before or after the line of code containing the **???**. \n",
    "* Questions marked **Q - VG** are for **VG level**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813da4a0-f9dd-4d0b-b463-919038ba1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c47b51e-1ccb-4f1e-9d2d-b9db126cf4ae",
   "metadata": {},
   "source": [
    "Load the data from the supplied CSV file into a Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3333d6-f2b6-4a20-83df-64e97e253e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df = pd.read_csv('countries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8f30be-6d1a-4bc9-b7d9-4bec2f3396d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564bab7-c6ea-4fce-9b3c-56d5cb12ebca",
   "metadata": {},
   "source": [
    "**Q1: How many countries does the dataframe contain?**\n",
    "(Show which function/s you use to find this out.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ad659f-ea57-42f1-9cec-18a969b64e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_countries = len(countries_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0adc50-05dc-4aef-8ce5-fc53f03e834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} countries in the dataset'.format(num_countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c78645c-1283-41a1-8ce4-bc59fb15cd5a",
   "metadata": {},
   "source": [
    "**Q2: Retrieve a list of continents from the dataframe?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47091a-31d4-408f-a873-d2e72f3604dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = np.unique(countries_df['continent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0136b-6c33-4131-b001-c5deba641caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "continents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5792475-fb41-4099-bd49-913a72466155",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Q3: What is the total population of all the countries listed in this dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56aec4b-a97c-4371-b3c2-fe4823e56645",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_population = countries_df['population'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9c55f-3ff6-4a1e-93e2-d42b3188d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The total population is {}.'.format(int(total_population)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11a43b2-6d5d-43d4-84e9-66edbdc102ca",
   "metadata": {},
   "source": [
    "**Q4: Create a dataframe containing 10 countries with the highest population.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142fbe3-2394-4a94-979e-a22b1234d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_populous_df = countries_df.nlargest(10, 'population')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2014e8d-0295-4e91-a137-74f704e241b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_populous_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd31f1-6720-4eb6-89ab-8bfb8dbcfc9a",
   "metadata": {},
   "source": [
    "**Q5: Add a new column in `countries_df` to record the overall GDP per country (product of population & per capita GDP).**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7eff2c-3194-4b54-985f-052ab35d65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "countries_df['gdp'] = countries_df['gdp_per_capita'] * countries_df['population']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df6a9b-bcfb-496e-ae93-a3f6d60db30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09a87c-e079-4a01-8d77-a908ba06bd9a",
   "metadata": {},
   "source": [
    "**Q - VG: Create a dataframe containing 10 countries with the lowest GDP per capita, among the countries with a population greater than 100 million.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41680f-5ce4-4fb5-897a-87685a1dc9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = countries_df[countries_df.population > 100e6].nsmallest(10, 'gdp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d8f85-b57f-4fc2-8120-ca6573f62471",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bf6da3-2d0d-43a6-b893-7129c14eb2e4",
   "metadata": {},
   "source": [
    "**Q6: Create a DataFrame that counts the number countries on each continent?**\n",
    "\n",
    "*Hint: `groupby`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e298911-32e8-4e80-9936-4c318a56619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_counts_df = countries_df.groupby('continent').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17580c46-d69b-4049-b901-923302f75076",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0de08-9eaf-46a2-82c2-38d2fba14e42",
   "metadata": {},
   "source": [
    "**Q7: Create a data frame showing the total population of each continent.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe828e4-b802-4d2b-ac10-cc1e1fbcf8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_populations_df = countries_df.groupby('continent')['population'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383256de-0de8-45cd-afd4-641ae692c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_populations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1805c121-be08-4c2a-b50b-fa7a7d76fbf9",
   "metadata": {},
   "source": [
    "Next, use the CSV file containing overall Covid-19 stats for various countires, and read the data into another Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fef65c-20c5-4026-96b7-85ad1bb99d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data_df = pd.read_csv('covid-countries-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89818918-f3d4-4a2b-8212-2e5d28c02eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "covid_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179ba1f1-6d29-4758-b7ea-3c57b74da4ed",
   "metadata": {},
   "source": [
    "**Q8: Count the number of countries for which the `total_tests` data is missing.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17e544-3ca3-4921-a545-335c3096346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tests_missing = covid_data_df['total_tests'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b5c69-1b75-4d87-877b-0f77a8c07f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The data for total tests is missing for {} countries.\".format(int(total_tests_missing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb68538e-31de-46f4-90ca-41a867595caa",
   "metadata": {},
   "source": [
    "Let's merge the two data frames, and compute some more metrics.\n",
    "\n",
    "**Q9: Merge `countries_df` with `covid_data_df` on the `location` column.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d43a4c-4a10-4801-9878-d92c366dc249",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = countries_df.merge(covid_data_df, how='inner', on='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956cfcc-b140-4f2a-9ccd-0c12ec9a6650",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c20bcc-37e3-49fa-8b03-c5a0211c6e17",
   "metadata": {},
   "source": [
    "**Q10: Add columns `tests_per_million`, `cases_per_million` and `deaths_per_million` into `combined_df`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3562523e-ab38-4418-93c7-2f0eceaaf190",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['tests_per_million'] = combined_df['total_tests'] * 1e6 / combined_df['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a33d3-8d00-4263-88d4-7e55b36406b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['cases_per_million'] = combined_df['total_cases'] * 1e6 / combined_df['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b5a50-3cbc-423f-b877-19893af19ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['deaths_per_million'] = combined_df['total_deaths'] * 1e6 / combined_df['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6bfd87-b8f5-4524-b7d9-30408db5faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d317be-2444-49aa-b831-851c98c83a46",
   "metadata": {},
   "source": [
    "**Q11: Create a dataframe with 10 countires that have highest number of tests per million people.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eeac4e-48bf-42a5-996d-335cfbf495d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_tests_df = combined_df.nlargest(10, 'tests_per_million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be996d74-a966-49a2-bc6c-1e1f31b6b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_tests_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2680d3d9-7302-473a-8fba-3aff9509a960",
   "metadata": {},
   "source": [
    "**Q12: Create a dataframe with 10 countires that have highest number of positive cases per million people.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfacca-f4f7-4bf1-88ed-99df3599e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_cases_df = combined_df.nlargest(10, 'cases_per_million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8fc15-b93d-42d8-808e-6816a1692838",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_cases_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d33ad-d79b-4c22-9be3-6e4ab74bdc75",
   "metadata": {},
   "source": [
    "**Q13: Create a dataframe with 10 countires that have highest number of deaths cases per million people?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fb841-d0db-449b-97a6-d3789a7d4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_deaths_df = combined_df.nlargest(10, 'deaths_per_million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815a5d99-48b7-4928-a710-8a16ef6242e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_deaths_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d588ed3e-7a0c-4b05-a0ce-b1d99cdccbd2",
   "metadata": {},
   "source": [
    "**Q - VG: Count number of countries that feature in both the lists of \"highest number of tests per million\" and \"highest number of cases per million\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a8e36-885e-450f-bafc-68be67b7fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.nlargest(10, 'tests_per_million')['location'].isin(combined_df.nlargest(10, 'cases_per_million')['location']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd8fb26-6332-4e34-8f0e-af79b4a12c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b9e74-6bb2-4b30-a488-4c2686bb0d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b67b162-bb67-40af-b9ff-dec6c671a932",
   "metadata": {},
   "source": [
    "**Q - VG: Count number of countries that feature in both the lists \"20 countries with lowest GDP per capita\" and \"20 countries with the lowest number of hospital beds per thousand population\". Only consider countries with a population higher than 10 million while creating the list.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcafdc4-ae2e-49ab-922f-faf1dab6d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[combined_df.population > 10e6].nsmallest(20, 'gdp_per_capita').isin(combined_df[combined_df.population > 10e6].nsmallest(20, 'hospital_beds_per_thousand'))['location'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a5dbe-1478-48de-85e3-926894ddb7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223c1e2-77c4-4820-96e8-a9a6a970b4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00df8d6e-b002-427c-b5a3-bd35996be773",
   "metadata": {},
   "source": [
    "# Part 3 - Exploration\n",
    "The object of *Part 3* is for you to reflect upon what kind of data is interesting to you and using an example dataset, examine and explain what the data is like and what kind of things you could find out using it. \n",
    "\n",
    "Pick a real-world dataset of your choice and perform an exploratory data analysis. Focus on documentation and presentation - this Jupyter notebook will also serve as a project report, so make sure to include detailed explanations wherever possible using Markdown cells.\n",
    "\n",
    "### Evaluation Criteria\n",
    "\n",
    "Your submission will be evaluated using the following criteria:\n",
    "\n",
    ">* Dataset must contain at least 5 columns and 500 rows of data\n",
    ">* You must ask and answer at least 4 questions about the dataset\n",
    ">* Your submission must include at least 4 visualizations (graphs) with axes, title_labels and any other annotations necessary to understand the graph. \n",
    ">* Your submission must include explanations using markdown cells, apart from the code.\n",
    ">* Your work must not be plagiarized i.e. copy-pasted for somewhere else.\n",
    "\n",
    "#### Dataset repositories: \n",
    "- [UCI repository](http://archive.ics.uci.edu/ml/index.php)\n",
    "- [Public datasets](https://github.com/awesomedata/awesome-public-datasets)\n",
    "- [Google dataset search](https://datasetsearch.research.google.com/)\n",
    "- [Kaggle datasets](https://www.kaggle.com/datasets?fileType=csv)\n",
    "\n",
    "#### Example datasets:\n",
    "- https://www.kaggle.com/datasnaek/youtube-new\n",
    "- https://www.kaggle.com/imdevskp/corona-virus-report\n",
    "- https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data\n",
    "\n",
    "#### Example Projects\n",
    "\n",
    "Refer to these projects for inspiration:\n",
    "\n",
    "* [Analyzing your browser history using Pandas & Seaborn](https://medium.com/free-code-camp/understanding-my-browsing-pattern-using-pandas-and-seaborn-162b97e33e51) by Kartik Godawat\n",
    "\n",
    "* [2019 State of Javscript Survey Results](https://2019.stateofjs.com/demographics/)\n",
    "\n",
    "* [2020 Stack Overflow Developer Survey Results](https://insights.stackoverflow.com/survey/2020)\n",
    "\n",
    "\n",
    "\n",
    "## Follow this step-by-step guide to work on your project.\n",
    "\n",
    "### Step 1: Select a real-world dataset \n",
    "\n",
    ">- Find an interesting dataset at any of the recommended repositories below.\n",
    ">- The data should be in CSV format, and should contain at least 5 columns and 500 rows\n",
    ">- Download the dataset using pandas read_csv function and an url. See example below. (Please note that when downloading from kaggle, you will have to amend this code.) Alternatively, supply the exact link from which you got the dataset and any necessary instructions to download, unpack, load into dataframe etc. in order to get it to work.\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "`url = 'https://raw.githubusercontent.com/cs109/2014_data/master/countries.csv'`\n",
    "\n",
    "`c = pd.read_csv(url)`\n",
    "\n",
    "\n",
    "### Step 2: Perform data preparation & cleaning\n",
    "\n",
    ">- Load the dataset into a data frame using Pandas.\n",
    ">- Explore the number of rows & columns, ranges of values etc.\n",
    ">- Handle missing, incorrect and invalid data.\n",
    ">- Perform any additional steps (parsing dates, creating additional columns, merging multiple dataset etc.).\n",
    ">- Give a summary of the dataset as it is now, e.g. size, type of categories (qualitative vs. quantitative), quality, distribution etc.. \n",
    "\n",
    "\n",
    "### Step 3: Perform exploratory analysis & visualization\n",
    "\n",
    ">- Compute the mean, sum, range and other interesting statistics for numeric columns.\n",
    ">- Explore distributions of numeric columns using histograms etc.\n",
    ">- Explore relationship between columns using scatter plots, bar charts etc.\n",
    ">- Make a note of interesting insights from the exploratory analysis.\n",
    "\n",
    "### Step 4: Ask & answer questions about the data - VG\n",
    "\n",
    ">- Ask at least 4 interesting questions about your dataset. What kind of analysis could you do on this data?\n",
    ">- Answer the questions either by computing the results using Numpy/Pandas or by plotting graphs using Matplotlib.\n",
    ">- Create new columns, merge multiple dataset and perform grouping/aggregation wherever necessary.\n",
    ">- Wherever you're using a library function from Pandas/Numpy/Matplotlib etc. explain briefly what it does.\n",
    "\n",
    "\n",
    "### Step 5: Summarize your inferences & write a conclusion\n",
    "\n",
    ">- Write a summary of what you've learned from the analysis.\n",
    ">- Include interesting insights and graphs from previous sections.\n",
    ">- **(VG)** Share ideas for future work on the same topic using other relevant datasets.\n",
    ">- Share links to resources you found useful during your analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c4562",
   "metadata": {},
   "source": [
    "INTRODUCTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15bdf4",
   "metadata": {},
   "source": [
    "The dataset I've chosen to work on is the Kaggle survey for data science and machine learning in 2021.\n",
    "Kaggle is a data science and machine learning community where people can share datasets and findings. They also host a bunch of competitions with real life problems often sponsored by real companies.\n",
    "\n",
    "For me the survey is interesting because we can ask some questions in regards to how people approach the topic today and since this is a topic im currently studying hopefully i can learn some valueable lessons in regards to how my approach to the topic differs from others today.\n",
    "\n",
    "I'll be analysing the different questions asked and present both the data inside but also try to correlate the data and draw some conclusions to deeper questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6228f5d5",
   "metadata": {},
   "source": [
    "PREPARATION & CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d18f69-c3fa-4aa6-b58f-b533870a7e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the used libraries in this analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb26bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the the raw csv file \n",
    "df_raw = pd.read_csv('2021_kaggle_ds_and_ml_survey_responses_only.csv')\n",
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89131ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat so columns are first row (actual question names) rather then current columns\n",
    "new_header = df_raw.iloc[0]\n",
    "df_col_mod = df_raw[1:]\n",
    "df_col_mod.columns = new_header\n",
    "df_col_mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying over the column modified dataframe to do some more cleaning on it\n",
    "df_modified = df_col_mod.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98ae90a",
   "metadata": {},
   "source": [
    "The dataset contains multiple choice questions, to make it easier to analyse all of the answers together i'll rewrite the questions, example:\n",
    "\n",
    "'What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Python' \n",
    "\n",
    "becomes\n",
    "\n",
    "'What programming languages do you use on a regular basis? (Select all that apply)' \n",
    "\n",
    "This works because the 'Answer' column will still contain the selected choice\n",
    "\n",
    "We do this before we melt the dataframe to save some iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44843049",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_modified.columns:\n",
    "    old_name = i\n",
    "    new_name = i.split('-')[0].strip()\n",
    "    df_modified.rename(columns={old_name: new_name}, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e70c9a",
   "metadata": {},
   "source": [
    "Looking at the questions asked in the survey, a lot of them require a lot of additional information in order to draw good conclusions from them. A question like:\n",
    "\"Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis? (Select all that apply)\"\n",
    "Its an interesting question to ask but only in relation to the field as a whole and not only those represented by the participants of the survey.\n",
    "Looking at the usage of big data products can give you a picture of the current state of the field but when restricted to those who participated in the survey it gets a bit more complicated.\n",
    "There are 15 different types of job titles that was available as an answer (Other being included) which means that without the data to understand whether or not this reflects the field we cannot draw good conclusions from it.\n",
    "Add to the fact that the platform has a focus on learning which only attracts a certain group of people and that the country representation isn't really diverse. You have a lot harder time to draw good conclusions from the survey that reflects the field as a whole.\n",
    "Because of it i choose to do a big abstraction from a majority of the questions in the survey in order to use the data to draw some good conclusions from it\n",
    "I saved the questions in \"question.txt\" if you choose to take look at them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop uninstereting questions from dataframe\n",
    "df_modified.columns\n",
    "for line in open('question.txt', 'r'):\n",
    "    df_modified = df_modified.drop(columns=[line.strip()]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c5e3c4",
   "metadata": {},
   "source": [
    "Since we'll be asking some questions with relations to other ones I'll add the index as a variable before i melt the dataframe for easier access to the values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07929a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modified['id'] = df_modified.index\n",
    "df_modified = df_modified.melt(id_vars=[\"id\"]) #Melts the dataframe (pivots it)\n",
    "df_modified.dropna(subset=[\"value\"], inplace=True) #Drops row with NaN answer\n",
    "df_modified.rename(columns={0: 'Question', 'value': 'Answer'}, inplace=True) #Rename columns to Question and Answer\n",
    "df_modified "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3f15e",
   "metadata": {},
   "source": [
    "Since the dataset is a survey from a data science and machine learning community, the data cannot be used to relect upon the field as a whole and ought only be viewed from a lens looking at a small subsection of it ,especially without knowing exactly who uses the platform. But considering Kaggle's popularity among people starting out or learning the field, a good framework to have viewing the data would be too look at it through the lens of someone studying the field moreso than someone already well established in it. \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463d88d1",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65078cbb",
   "metadata": {},
   "source": [
    "To make it easier and have less repetetive code i'll make a couple of functions primarilly for plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_unrelated(question,knd, yl, xl, figsz, fontsz, patchsz):\n",
    "    plt.figure(facecolor=\"white\") #Changes the figure color to white \n",
    "    df_sqr = df_modified[df_modified['Question'] == question]['Answer'].value_counts(normalize=True).multiply(100) #Counts the amount of times value appears, normalizses it and multiplys the number with 100\n",
    "    ax = df_sqr.plot(kind=knd, figsize=figsz, fontsize=fontsz, xlabel=xl, title=yl) #Plot the dataframe\n",
    "    if patchsz>0:\n",
    "        for i in ax.patches:\n",
    "            ax.text(i.get_width(), i.get_y(), str(round(i.get_width(), 2))+'%', fontsize=patchsz) #Gets every patch and adds the length of it to the right (this case % of answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_related(q1, q2, knd, yl, xl, figsz, fontsz, patchsz):\n",
    "    df_fir = df_modified[df_modified['Question'] == q1].copy()\n",
    "    df_sec = df_modified[df_modified['Question'] == q2].copy()\n",
    "    df_comb = df_fir.merge(df_sec, on=\"id\") #Merges the two dataframes\n",
    "    df_comb.drop(columns=['Question_x', 'Question_y'], inplace=True)\n",
    "    dct = {}\n",
    "    for i in df_comb['Answer_y'].unique(): #Find every unique value in the colukmn\n",
    "        dct[i] = df_comb[df_comb['Answer_y']== i]['Answer_x'].value_counts()\n",
    "    df_final = pd.DataFrame(dct)\n",
    "    df_final = df_final.divide(df_final.sum(axis=1), axis=0).multiply(100).sort_index() #Divide value by total answers and multiply by 100 to get %, then sort the dataframe by index\n",
    "    ax = df_final.plot(kind=knd, figsize=figsz, fontsize=fontsz)\n",
    "    ax.set_xlabel(xl, fontsize=fontsz) #Sets the label of the x axis (left side if horizontal bar plot)\n",
    "    ax.set_title(yl, fontsize=fontsz) #Sets the title of the plot\n",
    "    if patchsz>0:\n",
    "        for i in ax.patches: \n",
    "            if i.get_width()>0: \n",
    "                ax.text(i.get_width(), i.get_y(), str(round(i.get_width(), 2))+'%', fontsize=patchsz)\n",
    "    ax.legend(prop={'size': 8}) #Sets the legend size of the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b56d6",
   "metadata": {},
   "source": [
    "QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3028f",
   "metadata": {},
   "source": [
    "A Quick summary of the questions i'll be asking:\n",
    "    Basic Question regarding the dataset\n",
    "        How many questions were asked?\n",
    "        How many people took the survey\n",
    "\n",
    "    How does the distribution of survey participants look in terms of:\n",
    "        Country\n",
    "\n",
    "        Age\n",
    "\n",
    "        Gender\n",
    "        \n",
    "        Title\n",
    "        \n",
    "        Experience\n",
    "        \n",
    "        Usage of programming languages\n",
    "        \n",
    "        Recommended programming language to start with\n",
    "        \n",
    "        Usage of IDE\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8645a4",
   "metadata": {},
   "source": [
    "below is the list of questions from the survey we'll use in the analysis and the number of people that answered the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4419574",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Questions:\")\n",
    "for i in df_modified['Question'].unique():\n",
    "    print(f\"\\t{i}\")\n",
    "\n",
    "print(f\"\\n{len(df_modified['id'].unique())} people answered the survey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7897abb0",
   "metadata": {},
   "source": [
    "Country representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calls plot single question function to plot answers out\n",
    "plot_unrelated('In which country do you currently reside?', 'barh', 'In which country do you currently reside?', \"Name of country\", (10,10), 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a166899",
   "metadata": {},
   "source": [
    "In contrast to last years survey which i know had 42 different countries this years only allowed you to choose between 11.\n",
    "But same as last year india had the most representation with 29% which corrensponds to 7532 participants. \n",
    "This might make it harder to draw good concusions from the survey at least in terms of countries since we don't know whether or not this represent the field as a whole.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb53022a",
   "metadata": {},
   "source": [
    "Age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f392b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calls plot single question function to plot answers out\n",
    "plot_unrelated('What is your age (# years)?', \"barh\", 'What is your age (# years)?', \"Age group\", (15,10), 10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce24d9",
   "metadata": {},
   "source": [
    "Not unsuprisingly the younger generation is more represented then the older ones after the age group of 25-29 a decline starts to happen.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329ef73",
   "metadata": {},
   "source": [
    "Gender representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cee967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calls plot single question function to plot answers out\n",
    "plot_unrelated('What is your gender?', \"barh\", 'What is your gender?', \"Gender\", (15,10), 10, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e16ca7",
   "metadata": {},
   "source": [
    "About 80% of the participants were male, 19% female and slightly below 2% prefered to self-describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9166bf46",
   "metadata": {},
   "source": [
    "Education distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88069b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'What is the highest level of formal education that you have attained or plan to attain within the next 2 years?'\n",
    "plot_unrelated(q, \"barh\", q, \"Name of education\", (15,10), 10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b69cab",
   "metadata": {},
   "source": [
    "Almost 90% of the survey participants have attained or planned to a above bachelor's degree. This makes sense considering the nature of the topic. \n",
    "\n",
    "Because of how the question is written with (or planned to attain within 2 years) the data from this question is quite scewed. That is because participants that have already attained and current students are lumped into the same category. \n",
    "When we later on try to use this data to make other conclusions i'll take that into account and use other datapoints from survey in order to substantiate the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6757a4",
   "metadata": {},
   "source": [
    "Title distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f60b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Select the title most similar to your current role (or most recent title if retired):\"\n",
    "plot_unrelated(q, \"barh\", q, \"Name of title\", (15,10), 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d21389",
   "metadata": {},
   "source": [
    "As seen in the plot above, most of the participants are students which corresponds to 26,2% of the answers given.\n",
    "We'll use this datapoint later on in relation with education level to make sure our conclusions is sound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62cae13",
   "metadata": {},
   "source": [
    "Title and Education distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada08f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"Select the title most similar to your current role (or most recent title if retired):\"\n",
    "q2 = \"What is the highest level of formal education that you have attained or plan to attain within the next 2 years?\"\n",
    "plot_related(q1, q2, \"barh\", \"Title and Education distribution\", \"Education level\", (15,40), 20, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b657c59e",
   "metadata": {},
   "source": [
    "Besides developer relations/advocacy that has a equal parts bachelors and masters for every job masters is the more common degree to have. With exception for Research scientist where the majority had a doctoral. \n",
    "For students most are studying for a bachelor or a master.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f8828c",
   "metadata": {},
   "source": [
    "Experience distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8410178",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'For how many years have you been writing code and/or programming?'\n",
    "plot_unrelated(q, \"barh\", q, \"years of experience\", (15,10), 10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f47ea0",
   "metadata": {},
   "source": [
    "A majority of the users using Kaggle is newer to the field of data science and machine learning with roughly 53% having less then 3 years experience with writing code. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9e225e",
   "metadata": {},
   "source": [
    "Experience and Title distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f1d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"Select the title most similar to your current role (or most recent title if retired):\"\n",
    "q2 = 'For how many years have you been writing code and/or programming?'\n",
    "plot_related(q1, q2, \"barh\", \"Experience and Title distribution\", \"Title\", (15,25), 15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41752901",
   "metadata": {},
   "source": [
    "It's not a surprise to me that for the most part between 0-3 years of experience are amongst the top answers across the titles (with some edgecases) due to the nature of Kaggle being a community with focus on learning so it most likely draws the attention more so to people newer to the field. This means that it probably doesn't reflect the field as a whole so when we draw conclusions from datapoints we have to keep this in mind. \n",
    "\n",
    "Some notable differences between the data is for an example that for business analysts and product managers roughly 13 and 12% respectively answered that they've never written code before. If i'd had to pick two titles to be the most common to not write code it would probably been those two so it wasn't that much of a surprise for me.  \n",
    "\n",
    "Looking at something like machine learning engineer it's interesting to me that 3% have never written code before and 15% have less then 1 years of experience. Don't know whether or not this is because the title is relatively new and number of answers on the survey might not represent the field as a whole.  \n",
    "\n",
    "\n",
    "Let's assign a value to each label and calculate the avgerage years per title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dct = {\"5-10 years\": 7.5, \"20+ years\": 20, \"1-3 years\": 2, \"< 1 years\": 0.5, \"10-20 years\": 15, \"I have never written code\": 0, \"3-5 years\": 4}\n",
    "q1 = \"Select the title most similar to your current role (or most recent title if retired):\"\n",
    "q2 = 'For how many years have you been writing code and/or programming?'\n",
    "df_q1 = df_modified.loc[df_modified['Question'] == q1].copy()\n",
    "df_q1_cnt = df_q1['Answer'].value_counts()\n",
    "df_q1_cnt = pd.DataFrame(df_q1_cnt).reset_index().rename(columns={\"index\": \"Title\", \"Answer\": \"Number of answers\"}) #Resets the index\n",
    "df_q2 = df_modified.loc[df_modified['Question'] == q2].copy()\n",
    "df_comb = df_q1.merge(df_q2, on=\"id\")\n",
    "df_comb.drop(columns=['Question_x', 'Question_y', 'id'], inplace=True)\n",
    "\n",
    "for key, val in exp_dct.items():\n",
    "    df_comb['Answer_y'].loc[df_comb['Answer_y'] == key] = val\n",
    "df_comb['Answer_y'] = pd.to_numeric(df_comb['Answer_y'])\n",
    "df_comb.groupby('Answer_x')['Answer_y'].mean().sort_values(ascending=False).reset_index().rename(columns={\"Answer_x\": \"Title\", \"Answer_y\": \"Avg yrs of coding exp\"})\n",
    "df_comb = pd.DataFrame(df_comb.groupby('Answer_x')['Answer_y'].mean().sort_values(ascending=False)).reset_index().rename(columns={\"Answer_x\": \"Title\", \"Answer_y\": \"Avg yrs of coding exp\"})\n",
    "df_comb = df_comb.merge(df_q1_cnt, on='Title')\n",
    "df_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the dataframe above, the average years of experience is lead by research scientist at 8.5 years.\n",
    "To note the amount of answers with title database engineer and developer relations/advocacy is below 200 so in order to draw conclusions from those datapoints we'd need more data\n",
    "\n",
    "Students and people who are currently not employed is on the bottom of the list. with 2.3 and 3.4 average years respectively. Which makes sense due to the the title they hold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d20c71",
   "metadata": {},
   "source": [
    "Usage of programming languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af67fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"What programming languages do you use on a regular basis? (Select all that apply)\"\n",
    "plot_unrelated(q, \"barh\", q, \"Language\", (15,10), 10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60aa781",
   "metadata": {},
   "source": [
    "To almost no surprise python is the most commonly used programming language by survey participants at 33% and SQL follow at 16%. This makes sense because from at least my point of view those are the two easiest ones to get into"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8f511c",
   "metadata": {},
   "source": [
    "Language and Title distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95dff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"Select the title most similar to your current role (or most recent title if retired):\"\n",
    "q2 = \"What programming languages do you use on a regular basis? (Select all that apply)\"\n",
    "plot_related(q1, q2, \"barh\", \"Language and title distribution\", \"Name of title\", (15,40), 15, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481ba616",
   "metadata": {},
   "source": [
    "Some notable exceptions from the average when looking at the usage of progamming languages by title is statisticians usage of R and developer relations/advocacys usage of C++. Remember from the dataframe i showed above though that the answers for both of is quite low so we can't really draw good conclusions from this. But at least for statisticians it makes sense that R is the most common language used.\n",
    "Also for a title like software engineer it makes sense that Java, C++ and Javascript for an example are more common the rest of the titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3fe660",
   "metadata": {},
   "source": [
    "Language and Experience distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"For how many years have you been writing code and/or programming?\"\n",
    "q2 = \"What programming languages do you use on a regular basis? (Select all that apply)\"\n",
    "plot_related(q1, q2, \"barh\", \"Language and Experience Distribution\", \"Years of experience\", (15,30), 10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956bbd87",
   "metadata": {},
   "source": [
    "Looking at it from language usage by experience it follows a similiar pattern, noticably though you can see the usage of older languages such as Bash increase the more experience you have, probably due to having more prevelency at that point in time and have since stuck.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d13e98",
   "metadata": {},
   "source": [
    "Recommended programming language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3191adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"What programming language would you recommend an aspiring data scientist to learn first?\"\n",
    "plot_unrelated(q, \"barh\", q, \"Name of language\", (15,10), 10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c9c59",
   "metadata": {},
   "source": [
    "To almost no suprise python is the clear favorite among people to learn for data science and machine learning with R and SQL being second and third respectively at 1/16 of the answers compared to python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eec67d",
   "metadata": {},
   "source": [
    "Usage of IDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e01f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply)\"\n",
    "plot_unrelated(q, \"barh\", q, \"Name of IDE\", (15,10), 10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d49cb6",
   "metadata": {},
   "source": [
    "As seen above jupyter notebook is the most commonly used IDE by participants at 25% with vscode being the second most common at 15%. The least used one with an exception for \"None\" and \"Other\" is vim/emacs. Which makes sense considering their age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c592d",
   "metadata": {},
   "source": [
    "IDE vs Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f116403",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"For how many years have you been writing code and/or programming?\"\n",
    "q2 = \"Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply)\"\n",
    "plot_related(q1, q2, \"barh\", \"IDE and Experience distribution\", \"Years of Experience\", (15,30), 15, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a64f8a",
   "metadata": {},
   "source": [
    "Notably following the same trend as with experience and language usage, vim/emacs popularity increases the more experience the participants have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884980e",
   "metadata": {},
   "source": [
    "CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbc7f9f",
   "metadata": {},
   "source": [
    "We've looked at some questions from the Kaggle data science and machine learning survey for 2021 to draw some conclusions about their work\n",
    "\n",
    "India was the most represented country in the survey with 29% of the answers.\n",
    "A majority of the answers was between 18-29 years of age and 80% of the answers was male and 19% female.\n",
    "\n",
    "Almost 90% planned to attain within the next 2 years or had attained at least a bachelor's degree. 26% of the answers were currently students.\n",
    "Most common among all of the job titles were having a bachelor's or a master's degree with exception of research scientist having master's and doctoral degree.\n",
    "\n",
    "A majority of participants had less then 3 years of coding experience.\n",
    "The title with the highest average coding experience was research scientist at 8.5% and lowest was business analyst at 3.7%.\n",
    "We also found that python had a big dominance both in terms of usage but also as the by far most recommended language to learn first as an aspiring data scientist. Which feels good considering it's what we're learning today.\n",
    "We've found that a trend was shown by participants that the more experience they have the likelier the usage of older languages such as bash and IDE's such as vim/emcs were more prevenlant probably due to their age and prevelency at the time they started learning.   \n",
    "There was a similar disitribution of languages with Python and SQL being the most common with exception of statisticians whose most used language was R. There was also a higher use of C++, Java and Javascript within the software engineers.\n",
    "The most commonly used IDE was jupyter notebook.\n",
    "\n",
    "For future work, looking at older surveys of the same topic can be good to look for differences in these answers over the years. Something to look for in those surveys is also if a bigger shift has happended over the years, both as the field has grown and as time has passed. Was python always dominating the field or when did it rise to the top? Has the experience level of the field grown or lessened as the years has gone by?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
